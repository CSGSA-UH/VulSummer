{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import concurrent.futures\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import transformers\n",
        "import torch\n",
        "import re\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, logging\n",
        "from transformers import BitsAndBytesConfig, GemmaTokenizer, pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "6Iiy2FtqmGh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "tFct46X3mpqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
        "    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ],
      "metadata": {
        "id": "SXd9bTZd1aaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZsfBuZDeCL"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
      ],
      "metadata": {
        "id": "vITh0KVJ10qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1cF8fjrzVhM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def format_for_training(examples):\n",
        "    formatted_texts = []\n",
        "    for instruction, inp, out in zip(examples['instruction'], examples['input'], examples['output']):\n",
        "        formatted_text = f\"{instruction}\\n{inp}\\nResponse: {out}\"\n",
        "        formatted_texts.append(formatted_text)\n",
        "    return {'text': formatted_texts}\n",
        "\n",
        "# Load your dataset\n",
        "dataset = load_dataset('json', data_files='/content/drive/MyDrive/fine_tuning_dataset.json', split='train')\n",
        "\n",
        "# Apply the formatting function\n",
        "formatted_dataset = dataset.map(format_for_training, batched=True)\n",
        "\n",
        "# Verify that 'text' is now part of the dataset\n",
        "print(formatted_dataset['text'][0])  # This should print the first 'text' field to confirm it's correct"
      ],
      "metadata": {
        "id": "m7LZ7C3uVKfK",
        "outputId": "08357b44-816d-42c9-c92b-f3b1189bf1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "edd6e45a442349a59a30158ff03cafd3",
            "75ac1dd64db44184a5589d7aebd51fe9",
            "054a85047593486d89b13bb8f8a7facc",
            "39e1e25b1bc24e6d96d0538cb5f1a406",
            "f78ca9bb29f3403cbf72abca1cd1915c",
            "790a6ff78371454cbf13dc3202cc2d09",
            "b8454e7c924540f2a8b5a6a7af7369d4",
            "cd64503872a84697952b183651aaac23",
            "5e055eef953044e1a7f481b6d022c5a5",
            "8f3e60c1dfae4ccbbc90235213ba819c",
            "868ea401b1764c4f8c35e503b6d40f90",
            "dc438feea3ce43539b995e73527a34ee",
            "9a9a69750c9b412f84501411b58a1e7e",
            "d4de02b416f8487bb8a5092c2243ea85",
            "fdc386aa4e4140d6890e090d6ef4418c",
            "626570d5a0d543109dacdaf76854790b",
            "62aa310e46a04b89926f6cc490606db5",
            "2e2912ccc9ec4fc3aad4c19b31de4efa",
            "113bea303fda48c19fc11a1535448091",
            "8d070e8c8a984401afa672c8019621de",
            "f43d2f1e33c745459c1f6000e128b42a",
            "b12a6e27f306483191fb687f9fb3f082"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edd6e45a442349a59a30158ff03cafd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30871 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc438feea3ce43539b995e73527a34ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "Does the following function have a vulnerability? \n",
            "Function:\n",
            "static char *make_filename_safe(const char *filename TSRMLS_DC)\n",
            "{\n",
            "\tif (*filename && strncmp(filename, \":memory:\", sizeof(\":memory:\")-1)) {\n",
            "\t\tchar *fullpath = expand_filepath(filename, NULL TSRMLS_CC);\n",
            "\n",
            "\t\tif (!fullpath) {\n",
            "\t\t\treturn NULL;\n",
            "\t\t}\n",
            "\n",
            "\t\tif (PG(safe_mode) && (!php_checkuid(fullpath, NULL, CHECKUID_CHECK_FILE_AND_DIR))) {\n",
            "\t\t\tefree(fullpath);\n",
            "\t\t\treturn NULL;\n",
            "\t\t}\n",
            "\n",
            "\t\tif (php_check_open_basedir(fullpath TSRMLS_CC)) {\n",
            "\t\t\tefree(fullpath);\n",
            "\t\t\treturn NULL;\n",
            "\t\t}\n",
            "\t\treturn fullpath;\n",
            "\t}\n",
            "\treturn estrdup(filename);\n",
            "}\n",
            "Is the function vulnerable? Yes or No. Explain your answer in one sentence.\n",
            "Response: Yes, this function is vulnerable because it falls under the classification of: Weaknesses in this category are related to the management of permissions, privileges, and other security features that are used to perform access control.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If already loaded just pull model from Drive\n",
        "model_directory = \"/content/drive/MyDrive/Models\"\n",
        "\n",
        "model = FastLanguageModel.from_pretrained(model_directory)\n",
        "tokenizer = FastLanguageModel.from_pretrained(model_directory)"
      ],
      "metadata": {
        "id": "T1dJhBF9Ffez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],  # Tokenize the 'text' field\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"  # Ensure PyTorch tensors are returned\n",
        "    )\n",
        "\n",
        "# Tokenize the formatted dataset\n",
        "tokenized_dataset = formatted_dataset.map(tokenize_data, batched=True)\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "# Check the output to ensure correct formatting and tokenization\n",
        "for i in range(3):\n",
        "    print(tokenized_dataset[i]['input_ids'].shape, tokenized_dataset[i]['attention_mask'].shape)"
      ],
      "metadata": {
        "id": "-r1X5Y6jYAiN",
        "outputId": "3af12000-d114-48c3-bdae-b122da2952ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "391b31a9f5ea4cf0a4ed7d2d0f9aae22",
            "4d325e4f9ed84e6f9f39b39369d92ad9",
            "45d79efd5f1b4f3696ce35c7fb3eee23",
            "f010b90f21014a5fbf4b9f129930a75d",
            "c023a33e23a840138d8cc438c1f9b580",
            "b9d0aedcf43744e689589a7b0cab7a58",
            "058a8dce16e54406ad496bdbacda9565",
            "4008914bb6614758921f4b3100b7e8f3",
            "9a0c909e16144fa5b7c5f26370801987",
            "3f8b3fc21ba24a6eb9afa966e04ab7ff",
            "e9562048cf7640098d1f40291987ca74"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30871 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "391b31a9f5ea4cf0a4ed7d2d0f9aae22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512]) torch.Size([512])\n",
            "torch.Size([512]) torch.Size([512])\n",
            "torch.Size([512]) torch.Size([512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ],
      "metadata": {
        "id": "idAEIeSQ3xdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_Nn-89DhsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0437166e-a5a8-46df-a3d4-4d873ff80280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=4,                     # Increase number of processors if possible\n",
        "    packing=False,                          # Turn off packing if not needed, based on your context length\n",
        "    args = TrainingArguments(\n",
        "      output_dir=\"outputs\",                   # Output directory\n",
        "      per_device_train_batch_size=4,          # Batch size per device during training, adjust as per GPU memory\n",
        "      gradient_accumulation_steps=4,          # Number of updates steps to accumulate before performing a backward/update pass.\n",
        "      warmup_steps=100,                       # Number of steps to perform learning rate warmup\n",
        "      max_steps=60,                           # Total number of training steps to perform\n",
        "      learning_rate=3e-4,                     # Start with a slightly higher learning rate\n",
        "      fp16=not is_bfloat16_supported(),       # Use mixed precision if BFloat16 is not supported\n",
        "      bf16=is_bfloat16_supported(),           # Use BFloat16 if supported by the hardware\n",
        "      logging_steps=10,                       # Log every 10 steps\n",
        "      optim=\"adamw_8bit\",                     # Using 8-bit precision AdamW optimizer\n",
        "      weight_decay=0.02,                      # Slightly higher weight decay\n",
        "      lr_scheduler_type=\"cosine\",             # Using cosine annealing learning rate scheduler\n",
        "      seed=3407                               # Seed for reproducibility\n",
        "    ),\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "b5bffde6-29b7-4440-9a62-c2d617ba0be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 30,871 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 16 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 23:11, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.507700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.947800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.979300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.944400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f78253-86cf-4673-ff2b-923460c2b3fd",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "476.2773 seconds used for training.\n",
            "7.94 minutes used for training.\n",
            "Peak reserved memory = 7.535 GB.\n",
            "Peak reserved memory for training = 1.941 GB.\n",
            "Peak reserved memory % of max memory = 51.092 %.\n",
            "Peak reserved memory for training % of max memory = 13.161 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!"
      ],
      "metadata": {
        "id": "ekOmTR1hSNcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Given the summary and function, determine if the function contains the vulnerability.\",\n",
        "        '''void vulnerable_function(char *input) {\n",
        "              char buffer[10];\n",
        "              strcpy(buffer, input);\n",
        "        }, Is the function vulnerable? Yes or No. Explain your answer in one sentence.'''\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate response\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=64,\n",
        "    use_cache=True,\n",
        "    temperature=0.1,  # Higher temperature increases randomness\n",
        "    top_p=0.8,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "# Decode and clean up output\n",
        "decoded_responses = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "cleaned_responses = [response.split(\"Response:\\n\")[-1].strip() for response in decoded_responses]\n",
        "print(cleaned_responses[0])"
      ],
      "metadata": {
        "id": "kR3gIAX-SM2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26dbb88-0d54-4cc5-aaf0-3b04e25c8671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "\n",
            "### Input:\n",
            "void vulnerable_function(char *input) {\n",
            "              char buffer[10];\n",
            "              strcpy(buffer, input);\n",
            "        }, Is the function vulnerable? Yes or No. Explain your answer in one sentence.\n",
            "Response: Yes, this function is vulnerable because it falls under the classification of: The software reads data past the end, or before the beginning, of the intended buffer. Extended Description  This typically occurs when the pointer or its index is incremented or decremented to a position beyond the bounds of the buffer or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run multiple tests on the diversevul functions to see the preformance."
      ],
      "metadata": {
        "id": "CrSvZObor0lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "dataset = load_dataset('json', data_files='/content/drive/MyDrive/fine_tuning_dataset.json', split='train')\n",
        "\n",
        "# Print the structure of the first sample\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO-MA5rsSgZ8",
        "outputId": "9ff54436-3a37-4a26-85d0-5e3f3d45d630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Given the following summary and function, determine if the function contains the described vulnerability.', 'input': 'Does the following function have a vulnerability? \\nFunction:\\nstatic char *make_filename_safe(const char *filename TSRMLS_DC)\\n{\\n\\tif (*filename && strncmp(filename, \":memory:\", sizeof(\":memory:\")-1)) {\\n\\t\\tchar *fullpath = expand_filepath(filename, NULL TSRMLS_CC);\\n\\n\\t\\tif (!fullpath) {\\n\\t\\t\\treturn NULL;\\n\\t\\t}\\n\\n\\t\\tif (PG(safe_mode) && (!php_checkuid(fullpath, NULL, CHECKUID_CHECK_FILE_AND_DIR))) {\\n\\t\\t\\tefree(fullpath);\\n\\t\\t\\treturn NULL;\\n\\t\\t}\\n\\n\\t\\tif (php_check_open_basedir(fullpath TSRMLS_CC)) {\\n\\t\\t\\tefree(fullpath);\\n\\t\\t\\treturn NULL;\\n\\t\\t}\\n\\t\\treturn fullpath;\\n\\t}\\n\\treturn estrdup(filename);\\n}\\nIs the function vulnerable? Yes or No. Explain your answer in one sentence.', 'output': 'Yes, this function is vulnerable because it falls under the classification of: Weaknesses in this category are related to the management of permissions, privileges, and other security features that are used to perform access control.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "dataset = load_dataset('json', data_files='/content/drive/MyDrive/fine_tuning_dataset.json', split='train')\n",
        "\n",
        "# Filter the dataset for entries where the output does not start with \"Yes\"\n",
        "non_vulnerable_samples = dataset.filter(lambda example: not example['output'].strip().startswith(\"Yes\"))\n",
        "\n",
        "# Select 5 random examples from the filtered non-vulnerable dataset\n",
        "if len(non_vulnerable_samples) > 5:\n",
        "    random_indices = random.sample(range(0, len(non_vulnerable_samples)), 5)\n",
        "    samples = non_vulnerable_samples.select(random_indices)\n",
        "else:\n",
        "    samples = non_vulnerable_samples  # Use all available samples if less than 5\n",
        "\n",
        "# Define the instruction\n",
        "instruction = \"Given the following summary and function, determine if the function contains the described vulnerability.\"\n",
        "\n",
        "# Use the fine-tuned model to generate responses for each sampled function\n",
        "for func in samples:\n",
        "    # Extract the input part from the dataset\n",
        "    function_code = func['input'].replace('\\n', ' ')  # Format the function string to fit on one line if needed\n",
        "\n",
        "    # Generate the prompt as per your Alpaca prompt style\n",
        "    prompt = f\"{instruction}\\n{function_code}, Is the function vulnerable? Yes or No. Explain your answer in one sentence.\"\n",
        "\n",
        "    # Generate the input tensor\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to('cuda')\n",
        "\n",
        "    # Generate response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, temperature=0.1, top_p=0.8, num_return_sequences=1)\n",
        "\n",
        "    # Decode and clean up output\n",
        "    decoded_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"\\nFunction: {function_code[:60]}...\")  # Print part of the function to track\n",
        "    print(f\"Response: {decoded_response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5-sRir2Gel4",
        "outputId": "6d79f821-6c86-4d96-82c6-ed42d9358c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Function: Does the following function have a vulnerability?  Function:...\n",
            "Response: Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "Does the following function have a vulnerability?  Function: nautilus_file_set_permissions (NautilusFile *file,  \t\t\t       guint32 new_permissions, \t\t\t       NautilusFileOperationCallback callback, \t\t\t       gpointer callback_data) { \tGFileInfo *info; \tGError *error;  \tif (!nautilus_file_can_set_permissions (file)) { \t\t/* Claim that something changed even if the permission change failed. \t\t * This makes it easier for some clients who see the \"reverting\" \t\t * to the old permissions as \"changing back\". \t\t */ \t\tnautilus_file_changed (file); \t\terror = g_error_new (G_IO_ERROR, G_IO_ERROR_PERMISSION_DENIED, \t\t\t\t     _(\"Not allowed to set permissions\")); \t\t(* callback) (file, NULL, error, callback_data); \t\tg_error_free (error); \t\treturn; \t} \t\t\t        \t/* Test the permissions-haven't-changed case explicitly \t * because we don't want to send the file-changed signal if \t * nothing changed. \t */ \tif (new_permissions == file->details->permissions) { \t\t(* callback) (file, NULL, NULL, callback_data); \t\treturn; \t}  \tinfo = g_file_info_new (); \tg_file_info_set_attribute_uint32 (info, G_FILE_ATTRIBUTE_UNIX_MODE, new_permissions); \tnautilus_file_set_attributes (file, info, callback, callback_data); \tg_object_unref (info); } Is the function vulnerable? Yes or No. Explain your answer in one sentence., Is the function vulnerable? Yes or No. Explain your answer in one sentence. Response: Yes, this function is vulnerable because it falls under the classification of: The software reads data past the end, or before the beginning, of the intended buffer. Extended Description  This typically occurs when the pointer or its index is incremented or decremented to a position beyond the bounds of the buffer or\n",
            "\n",
            "Function: Does the following function have a vulnerability?  Function:...\n",
            "Response: Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "Does the following function have a vulnerability?  Function: end_update(JOIN *join, JOIN_TAB *join_tab __attribute__((unused)), \t   bool end_of_records) {   TABLE *const table= join_tab->table;   ORDER   *group;   int\t  error;   DBUG_ENTER(\"end_update\");    if (end_of_records)     DBUG_RETURN(NESTED_LOOP_OK);    join->found_records++;   copy_fields(join_tab->tmp_table_param);\t// Groups are copied twice.   /* Make a key of group index */   for (group=table->group ; group ; group=group->next)   {     Item *item= *group->item;     if (group->fast_field_copier_setup != group->field)     {       DBUG_PRINT(\"info\", (\"new setup %p -> %p\",                           group->fast_field_copier_setup,                           group->field));       group->fast_field_copier_setup= group->field;       group->fast_field_copier_func=         item->setup_fast_field_copier(group->field);     }     item->save_org_in_field(group->field, group->fast_field_copier_func);     /* Store in the used key if the field was 0 */     if (item->maybe_null)       group->buff[-1]= (char) group->field->is_null();   }   if (!table->file->ha_index_read_map(table->record[1],                                       join_tab->tmp_table_param->group_buff,                                       HA_WHOLE_KEY,                                       HA_READ_KEY_EXACT))   {\t\t\t\t\t\t/* Update old record */     restore_record(table,record[1]);     update_tmptable_sum_func(join->sum_funcs,table);     if (unlikely((error= table->file->ha_update_tmp_row(table->record[1],                                                         table->record[0]))))     {       table->file->ha_end_update(table->record[1],                                                         table->record[0]);       DBUG_RETURN(error);     }     table->file->ha_end_update(table->record[1],                                                         table->record[0]);   }   DBUG\n",
            "\n",
            "Function: Does the following function have a vulnerability?  Function:...\n",
            "Response: Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "Does the following function have a vulnerability?  Function: static void io_poll_remove_all(struct io_ring_ctx *ctx) { \tstruct hlist_node *tmp; \tstruct io_kiocb *req; \tint i;  \tspin_lock_irq(&ctx->completion_lock); \tfor (i = 0; i < (1U << ctx->cancel_hash_bits); i++) { \t\tstruct hlist_head *list;  \t\tlist = &ctx->cancel_hash[i]; \t\thlist_for_each_entry_safe(req, tmp, list, hash_node) \t\t\tio_poll_remove_one(req); \t} \tspin_unlock_irq(&ctx->completion_lock); } Is the function vulnerable? Yes or No. Explain your answer in one sentence., Is the function vulnerable? Yes or No. Explain your answer in one sentence. Response: Yes, this function is vulnerable because it falls under the classification of: The software reads data past the end, or before the beginning, of the intended buffer. Extended Description  This typically occurs when the pointer or its index is incremented or decremented to a position beyond the bounds of the buffer or\n",
            "\n",
            "Function: Does the following function have a vulnerability?  Function:...\n",
            "Response: Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "Does the following function have a vulnerability?  Function: camel_imapx_server_schedule_idle_sync (CamelIMAPXServer *is, \t\t\t\t       CamelIMAPXMailbox *mailbox, \t\t\t\t       GCancellable *cancellable, \t\t\t\t       GError **error) { \tg_return_val_if_fail (CAMEL_IS_IMAPX_SERVER (is), FALSE); \tif (mailbox) \t\tg_return_val_if_fail (CAMEL_IS_IMAPX_MAILBOX (mailbox), FALSE);  \tif (!camel_imapx_server_stop_idle_sync (is, cancellable, error)) \t\treturn FALSE;  \tif (!camel_imapx_server_can_use_idle (is)) \t\treturn TRUE;  \tg_mutex_lock (&is->priv->idle_lock);  \tif (is->priv->idle_state != IMAPX_IDLE_STATE_OFF) { \t\tg_warn_if_fail (is->priv->idle_state == IMAPX_IDLE_STATE_OFF);  \t\tg_mutex_unlock (&is->priv->idle_lock);  \t\treturn FALSE; \t}  \tg_warn_if_fail (is->priv->idle_cancellable == NULL);  \tis->priv->idle_cancellable = g_cancellable_new (); \tis->priv->idle_stamp++;  \tif (is->priv->idle_pending) { \t\tg_source_destroy (is->priv->idle_pending); \t\tg_source_unref (is->priv->idle_pending); \t}  \tg_clear_object (&is->priv->idle_mailbox); \tif (mailbox) \t\tis->priv->idle_mailbox = g_object_ref (mailbox);  \tis->priv->idle_state = IMAPX_IDLE_STATE_SCHEDULED; \tis->priv->idle_pending = g_timeout_source_new_seconds (is->priv->idle_timeout, \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "Function: Does the following function have a vulnerability?  Function:...\n",
            "Response: Given the following summary and function, determine if the function contains the described vulnerability.\n",
            "Does the following function have a vulnerability?  Function: vte_sequence_handler_cs (VteTerminal *terminal, GValueArray *params) { \tlong start=-1, end=-1, rows; \tGValue *value; \tVteScreen *screen;  \t/* We require two parameters.  Anything less is a reset. */ \tscreen = terminal->pvt->screen; \tif ((params == NULL) || (params->n_values < 2)) { \t\tscreen->scrolling_restricted = FALSE; \t\treturn; \t} \t/* Extract the two values. */ \tvalue = g_value_array_get_nth(params, 0); \tif (G_VALUE_HOLDS_LONG(value)) { \t\tstart = g_value_get_long(value); \t} \tvalue = g_value_array_get_nth(params, 1); \tif (G_VALUE_HOLDS_LONG(value)) { \t\tend = g_value_get_long(value); \t} \t/* Catch garbage. */ \trows = terminal->row_count; \tif (start <= 0 || start >= rows) { \t\tstart = 0; \t} \tif (end <= 0 || end >= rows) { \t\tend = rows - 1; \t} \t/* Set the right values. */ \tscreen->scrolling_region.start = start; \tscreen->scrolling_region.end = end; \tscreen->scrolling_restricted = TRUE; \t/* Special case -- run wild, run free. */ \tif (screen->scrolling_region.start == 0 && \t    screen->scrolling_region.end == rows - 1) { \t\tscreen->scrolling_restricted = FALSE; \t} \tscreen->cursor_current.row = screen->insert_delta + start; \tscreen->cursor_current.col = 0; } Is the function vulnerable? Yes or No. Explain your answer in one sentence., Is the function vulnerable? Yes or No. Explain your answer in one sentence.\n",
            "Response: Yes, this function is vulnerable because it falls under the classification of: The software reads data past the end, or before the beginning, of the intended buffer. Extended Description  This typically occurs when the pointer or its index is incremented or decremented to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ],
      "metadata": {
        "id": "uMuVrWbjAzhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_directory = \"/content/drive/MyDrive/Models\"  # Change 'YourModelFolder' to your desired folder name\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(model_directory)\n",
        "tokenizer.save_pretrained(model_directory)"
      ],
      "metadata": {
        "id": "upcOlWe7A1vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9579f7-5eab-4d82-9838-82e8e2956e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Models/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Models/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Models/tokenizer.model',\n",
              " '/content/drive/MyDrive/Models/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ],
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edd6e45a442349a59a30158ff03cafd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75ac1dd64db44184a5589d7aebd51fe9",
              "IPY_MODEL_054a85047593486d89b13bb8f8a7facc",
              "IPY_MODEL_39e1e25b1bc24e6d96d0538cb5f1a406"
            ],
            "layout": "IPY_MODEL_f78ca9bb29f3403cbf72abca1cd1915c"
          }
        },
        "75ac1dd64db44184a5589d7aebd51fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_790a6ff78371454cbf13dc3202cc2d09",
            "placeholder": "​",
            "style": "IPY_MODEL_b8454e7c924540f2a8b5a6a7af7369d4",
            "value": "Generating train split: "
          }
        },
        "054a85047593486d89b13bb8f8a7facc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd64503872a84697952b183651aaac23",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e055eef953044e1a7f481b6d022c5a5",
            "value": 1
          }
        },
        "39e1e25b1bc24e6d96d0538cb5f1a406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f3e60c1dfae4ccbbc90235213ba819c",
            "placeholder": "​",
            "style": "IPY_MODEL_868ea401b1764c4f8c35e503b6d40f90",
            "value": " 30871/0 [00:02&lt;00:00, 13923.73 examples/s]"
          }
        },
        "f78ca9bb29f3403cbf72abca1cd1915c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "790a6ff78371454cbf13dc3202cc2d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8454e7c924540f2a8b5a6a7af7369d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd64503872a84697952b183651aaac23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5e055eef953044e1a7f481b6d022c5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f3e60c1dfae4ccbbc90235213ba819c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868ea401b1764c4f8c35e503b6d40f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc438feea3ce43539b995e73527a34ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a9a69750c9b412f84501411b58a1e7e",
              "IPY_MODEL_d4de02b416f8487bb8a5092c2243ea85",
              "IPY_MODEL_fdc386aa4e4140d6890e090d6ef4418c"
            ],
            "layout": "IPY_MODEL_626570d5a0d543109dacdaf76854790b"
          }
        },
        "9a9a69750c9b412f84501411b58a1e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62aa310e46a04b89926f6cc490606db5",
            "placeholder": "​",
            "style": "IPY_MODEL_2e2912ccc9ec4fc3aad4c19b31de4efa",
            "value": "Map: 100%"
          }
        },
        "d4de02b416f8487bb8a5092c2243ea85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_113bea303fda48c19fc11a1535448091",
            "max": 30871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d070e8c8a984401afa672c8019621de",
            "value": 30871
          }
        },
        "fdc386aa4e4140d6890e090d6ef4418c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43d2f1e33c745459c1f6000e128b42a",
            "placeholder": "​",
            "style": "IPY_MODEL_b12a6e27f306483191fb687f9fb3f082",
            "value": " 30871/30871 [00:00&lt;00:00, 50835.80 examples/s]"
          }
        },
        "626570d5a0d543109dacdaf76854790b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62aa310e46a04b89926f6cc490606db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2912ccc9ec4fc3aad4c19b31de4efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "113bea303fda48c19fc11a1535448091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d070e8c8a984401afa672c8019621de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f43d2f1e33c745459c1f6000e128b42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12a6e27f306483191fb687f9fb3f082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "391b31a9f5ea4cf0a4ed7d2d0f9aae22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d325e4f9ed84e6f9f39b39369d92ad9",
              "IPY_MODEL_45d79efd5f1b4f3696ce35c7fb3eee23",
              "IPY_MODEL_f010b90f21014a5fbf4b9f129930a75d"
            ],
            "layout": "IPY_MODEL_c023a33e23a840138d8cc438c1f9b580"
          }
        },
        "4d325e4f9ed84e6f9f39b39369d92ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d0aedcf43744e689589a7b0cab7a58",
            "placeholder": "​",
            "style": "IPY_MODEL_058a8dce16e54406ad496bdbacda9565",
            "value": "Map: 100%"
          }
        },
        "45d79efd5f1b4f3696ce35c7fb3eee23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4008914bb6614758921f4b3100b7e8f3",
            "max": 30871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a0c909e16144fa5b7c5f26370801987",
            "value": 30871
          }
        },
        "f010b90f21014a5fbf4b9f129930a75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f8b3fc21ba24a6eb9afa966e04ab7ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e9562048cf7640098d1f40291987ca74",
            "value": " 30871/30871 [03:33&lt;00:00, 305.78 examples/s]"
          }
        },
        "c023a33e23a840138d8cc438c1f9b580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d0aedcf43744e689589a7b0cab7a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058a8dce16e54406ad496bdbacda9565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4008914bb6614758921f4b3100b7e8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0c909e16144fa5b7c5f26370801987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f8b3fc21ba24a6eb9afa966e04ab7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9562048cf7640098d1f40291987ca74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}