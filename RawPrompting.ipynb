{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This approch will be to load in our CVE dataset, and the DiverseVul Dataset which willhave 'func' - function, 'target' - 1 or 0 value for vul or not, 'cwe' - A category code, 'message' - commit message.\n",
        "# We then take this data and summarize each 'func' with an LLM that describes and vulenabilites in the code, and then trys to match the vulnerability summary to the CVE summary.\n",
        "# Then after we mark each 'func' as vulnerable or not we compare the 'target' label with the prediction and record the recall, accuracy, and F1 scores."
      ],
      "metadata": {
        "id": "gTO4R2xFMj1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGZkZpUqLeUA",
        "outputId": "c5fa345c-156e-40e1-80e5-27049ba30d77",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.1-py3-none-any.whl (326 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/326.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m317.4/326.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Collecting tensorflow-probability\n",
            "  Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.25.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Installing collected packages: tensorflow-probability\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.23.0\n",
            "    Uninstalling tensorflow-probability-0.23.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.23.0\n",
            "Successfully installed tensorflow-probability-0.24.0\n"
          ]
        }
      ],
      "source": [
        "### 1. Install the Necessary Libraries\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "!pip install transformers torch\n",
        "!pip install --upgrade tensorflow-probability\n",
        "!pip install --upgrade --quiet openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Define the path to your JSON file\n",
        "code_data = \"/content/drive/MyDrive/processedData.json\"\n",
        "cve_summaries_path = \"/content/drive/MyDrive/training_data.csv\"\n",
        "\n",
        "# This will store the corrected JSON objects\n",
        "corrected_data = [] # code_data\n",
        "\n",
        "# Read the file and convert each JSON object correctly\n",
        "with open(code_data, 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            # Try to parse each line as a separate JSON object\n",
        "            json_object = json.loads(line)\n",
        "            corrected_data.append(json_object)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error decoding JSON from line:\", line)\n",
        "\n",
        "print(corrected_data[0])\n",
        "\n",
        "# Load CSV data\n",
        "df = pd.read_csv(cve_summaries_path)\n",
        "\n",
        "print(\"\\nCSV Data Sample:\")\n",
        "print(df.head())  # Display the first 5 rows of the DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNZsY_trLnEM",
        "outputId": "17acd208-0133-4a6b-bc6b-a08b8d7224b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'func': 'int _gnutls_ciphertext2compressed(gnutls_session_t session,\\n\\t\\t\\t\\t  opaque * compress_data,\\n\\t\\t\\t\\t  int compress_size,\\n\\t\\t\\t\\t  gnutls_datum_t ciphertext, uint8 type)\\n{\\n    uint8 MAC[MAX_HASH_SIZE];\\n    uint16 c_length;\\n    uint8 pad;\\n    int length;\\n    mac_hd_t td;\\n    uint16 blocksize;\\n    int ret, i, pad_failed = 0;\\n    uint8 major, minor;\\n    gnutls_protocol_t ver;\\n    int hash_size =\\n\\t_gnutls_hash_get_algo_len(session->security_parameters.\\n\\t\\t\\t\\t  read_mac_algorithm);\\n\\n    ver = gnutls_protocol_get_version(session);\\n    minor = _gnutls_version_get_minor(ver);\\n    major = _gnutls_version_get_major(ver);\\n\\n    blocksize = _gnutls_cipher_get_block_size(session->security_parameters.\\n\\t\\t\\t\\t\\t      read_bulk_cipher_algorithm);\\n\\n    /* initialize MAC \\n     */\\n    td = mac_init(session->security_parameters.read_mac_algorithm,\\n\\t\\t  session->connection_state.read_mac_secret.data,\\n\\t\\t  session->connection_state.read_mac_secret.size, ver);\\n\\n    if (td == GNUTLS_MAC_FAILED\\n\\t&& session->security_parameters.read_mac_algorithm !=\\n\\tGNUTLS_MAC_NULL) {\\n\\tgnutls_assert();\\n\\treturn GNUTLS_E_INTERNAL_ERROR;\\n    }\\n\\n\\n    /* actual decryption (inplace)\\n     */\\n    switch (_gnutls_cipher_is_block\\n\\t    (session->security_parameters.read_bulk_cipher_algorithm)) {\\n    case CIPHER_STREAM:\\n\\tif ((ret = _gnutls_cipher_decrypt(session->connection_state.\\n\\t\\t\\t\\t\\t  read_cipher_state,\\n\\t\\t\\t\\t\\t  ciphertext.data,\\n\\t\\t\\t\\t\\t  ciphertext.size)) < 0) {\\n\\t    gnutls_assert();\\n\\t    return ret;\\n\\t}\\n\\n\\tlength = ciphertext.size - hash_size;\\n\\n\\tbreak;\\n    case CIPHER_BLOCK:\\n\\tif ((ciphertext.size < blocksize)\\n\\t    || (ciphertext.size % blocksize != 0)) {\\n\\t    gnutls_assert();\\n\\t    return GNUTLS_E_DECRYPTION_FAILED;\\n\\t}\\n\\n\\tif ((ret = _gnutls_cipher_decrypt(session->connection_state.\\n\\t\\t\\t\\t\\t  read_cipher_state,\\n\\t\\t\\t\\t\\t  ciphertext.data,\\n\\t\\t\\t\\t\\t  ciphertext.size)) < 0) {\\n\\t    gnutls_assert();\\n\\t    return ret;\\n\\t}\\n\\n\\t/* ignore the IV in TLS 1.1.\\n\\t */\\n\\tif (session->security_parameters.version >= GNUTLS_TLS1_1) {\\n\\t    ciphertext.size -= blocksize;\\n\\t    ciphertext.data += blocksize;\\n\\n\\t    if (ciphertext.size == 0) {\\n\\t\\tgnutls_assert();\\n\\t\\treturn GNUTLS_E_DECRYPTION_FAILED;\\n\\t    }\\n\\t}\\n\\n\\tpad = ciphertext.data[ciphertext.size - 1] + 1;\\t/* pad */\\n\\n\\tlength = ciphertext.size - hash_size - pad;\\n\\n\\tif (pad > ciphertext.size - hash_size) {\\n\\t    gnutls_assert();\\n\\t    /* We do not fail here. We check below for the\\n\\t     * the pad_failed. If zero means success.\\n\\t     */\\n\\t    pad_failed = GNUTLS_E_DECRYPTION_FAILED;\\n\\t}\\n\\n\\t/* Check the pading bytes (TLS 1.x)\\n\\t */\\n\\tif (ver >= GNUTLS_TLS1)\\n\\t    for (i = 2; i < pad; i++) {\\n\\t\\tif (ciphertext.data[ciphertext.size - i] !=\\n\\t\\t    ciphertext.data[ciphertext.size - 1])\\n\\t\\t    pad_failed = GNUTLS_E_DECRYPTION_FAILED;\\n\\t    }\\n\\n\\tbreak;\\n    default:\\n\\tgnutls_assert();\\n\\treturn GNUTLS_E_INTERNAL_ERROR;\\n    }\\n\\n    if (length < 0)\\n\\tlength = 0;\\n    c_length = _gnutls_conv_uint16((uint16) length);\\n\\n    /* Pass the type, version, length and compressed through\\n     * MAC.\\n     */\\n    if (td != GNUTLS_MAC_FAILED) {\\n\\t_gnutls_hmac(td,\\n\\t\\t     UINT64DATA(session->connection_state.\\n\\t\\t\\t\\tread_sequence_number), 8);\\n\\n\\t_gnutls_hmac(td, &type, 1);\\n\\tif (ver >= GNUTLS_TLS1) {\\t/* TLS 1.x */\\n\\t    _gnutls_hmac(td, &major, 1);\\n\\t    _gnutls_hmac(td, &minor, 1);\\n\\t}\\n\\t_gnutls_hmac(td, &c_length, 2);\\n\\n\\tif (length > 0)\\n\\t    _gnutls_hmac(td, ciphertext.data, length);\\n\\n\\tmac_deinit(td, MAC, ver);\\n    }\\n\\n    /* This one was introduced to avoid a timing attack against the TLS\\n     * 1.0 protocol.\\n     */\\n    if (pad_failed != 0)\\n\\treturn pad_failed;\\n\\n    /* HMAC was not the same. \\n     */\\n    if (memcmp(MAC, &ciphertext.data[length], hash_size) != 0) {\\n\\tgnutls_assert();\\n\\treturn GNUTLS_E_DECRYPTION_FAILED;\\n    }\\n\\n    /* copy the decrypted stuff to compress_data.\\n     */\\n    if (compress_size < length) {\\n\\tgnutls_assert();\\n\\treturn GNUTLS_E_INTERNAL_ERROR;\\n    }\\n    memcpy(compress_data, ciphertext.data, length);\\n\\n    return length;\\n}', 'target': 1, 'cwe': [], 'message': 'added an extra check while checking the padding.'}\n",
            "\n",
            "CSV Data Sample:\n",
            "   cwe_code                                            summary\n",
            "0       352  352 - a crosssite request forgery vulnerabilit...\n",
            "1       732  732 - missing permission checks in various api...\n",
            "2       639  639 - jenkins google compute engine plugin 411...\n",
            "3        79  79 - crosssite scripting xss in dolibarr erpcr...\n",
            "4        89  89 - sql injection vulnerability in dolibarr e...\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import re\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client with your API key\n",
        "client = OpenAI(\n",
        "    api_key=\"sk-proj-PR4DTt7N1tlbvJ8QzTxiT3BlbkFJf2t1Sc37vC0UkbCOUhJx\",\n",
        ")\n",
        "\n",
        "# Define the prompt base\n",
        "prompt_base = \"Analyze the following function for security vulnerabilities, if it is vulnerable respond with why if not respond with the code is clean: \"\n",
        "\n",
        "# Function to get a prediction from ChatGPT\n",
        "def chat_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    text = response.choices[0].message.content.strip()\n",
        "    print(\"Full Response:\", text)\n",
        "    # Define a more nuanced regular expression to determine if the function is not vulnerable\n",
        "    not_vulnerable_patterns = [\n",
        "        r'\\bis (not|secure|safe)\\b',\n",
        "        r'\\b(no significant security vulnerabilities)\\b',\n",
        "        r'\\b(no|without) obvious vulnerabilities\\b',\n",
        "        r'\\btherefore, it is not vulnerable\\b',\n",
        "        r'\\bclean'\n",
        "    ]\n",
        "    # Check if any of the 'not vulnerable' patterns are matched\n",
        "    if any(re.search(pattern, text, re.IGNORECASE) for pattern in not_vulnerable_patterns):\n",
        "        return 0\n",
        "    # If no patterns match, check for vulnerability patterns\n",
        "    vulnerable_patterns = [\n",
        "        r'\\bvulnerable\\b',\n",
        "        r'\\brisk\\b',\n",
        "        r'\\bunsafe\\b',\n",
        "        r'\\bdanger\\b',\n",
        "        r'\\binsecure\\b'\n",
        "    ]\n",
        "    if any(re.search(pattern, text, re.IGNORECASE) for pattern in vulnerable_patterns):\n",
        "        return 1\n",
        "    return 0  # Default to 0 if no clear conclusion can be drawn"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "IJ5jBN-4aXtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_functions = random.sample(corrected_data, 10)\n",
        "\n",
        "targets = []\n",
        "predictions = []\n",
        "\n",
        "for function in random_functions:\n",
        "    function_text = function[\"func\"]\n",
        "    target = function.get(\"target\")\n",
        "    if target is None:\n",
        "        print(\"Error: No target found in JSON object\")\n",
        "        continue  # Skip this iteration if target is missing\n",
        "\n",
        "    target = int(target)  # Ensure target is an integer\n",
        "    prediction = chat_gpt(prompt_base + function_text)\n",
        "\n",
        "    targets.append(target)\n",
        "    predictions.append(prediction)\n",
        "\n",
        "    # Print the entire JSON object for the function\n",
        "    print(\"JSON Object:\", json.dumps(function, indent=4))  # Pretty print JSON object\n",
        "    print(\"Predicted:\", prediction, \"Actual:\", target)\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "accuracy = accuracy_score(targets, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "VOlgaVgbbtBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd15924-c336-46f4-e513-b1850cf3a647",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Response: The given function does not appear to have any obvious security vulnerabilities. The function is creating a directory using parameters passed in and then closing the file once the directory is successfully created. It does not directly deal with user input or external data that could lead to security vulnerabilities. The function seems clean in terms of security.\n",
            "JSON Object: {\n",
            "    \"func\": \"NTSTATUS create_directory(connection_struct *conn, struct smb_request *req,\\n\\t\\t\\t  struct smb_filename *smb_dname)\\n{\\n\\tNTSTATUS status;\\n\\tfiles_struct *fsp;\\n\\n\\tstatus = SMB_VFS_CREATE_FILE(\\n\\t\\tconn,\\t\\t\\t\\t\\t/* conn */\\n\\t\\treq,\\t\\t\\t\\t\\t/* req */\\n\\t\\t0,\\t\\t\\t\\t\\t/* root_dir_fid */\\n\\t\\tsmb_dname,\\t\\t\\t\\t/* fname */\\n\\t\\tFILE_READ_ATTRIBUTES,\\t\\t\\t/* access_mask */\\n\\t\\tFILE_SHARE_NONE,\\t\\t\\t/* share_access */\\n\\t\\tFILE_CREATE,\\t\\t\\t\\t/* create_disposition*/\\n\\t\\tFILE_DIRECTORY_FILE,\\t\\t\\t/* create_options */\\n\\t\\tFILE_ATTRIBUTE_DIRECTORY,\\t\\t/* file_attributes */\\n\\t\\t0,\\t\\t\\t\\t\\t/* oplock_request */\\n\\t\\t0,\\t\\t\\t\\t\\t/* allocation_size */\\n\\t\\t0,\\t\\t\\t\\t\\t/* private_flags */\\n\\t\\tNULL,\\t\\t\\t\\t\\t/* sd */\\n\\t\\tNULL,\\t\\t\\t\\t\\t/* ea_list */\\n\\t\\t&fsp,\\t\\t\\t\\t\\t/* result */\\n\\t\\tNULL);\\t\\t\\t\\t\\t/* pinfo */\\n\\n\\tif (NT_STATUS_IS_OK(status)) {\\n\\t\\tclose_file(req, fsp, NORMAL_CLOSE);\\n\\t}\\n\\n\\treturn status;\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [],\n",
            "    \"message\": \"Fix bug #10229 - No access check verification on stream files.\\n\\nhttps://bugzilla.samba.org/show_bug.cgi?id=10229\\n\\nWe need to check if the requested access mask\\ncould be used to open the underlying file (if\\nit existed), as we're passing in zero for the\\naccess mask to the base filename.\\n\\nSigned-off-by: Jeremy Allison <jra@samba.org>\\nReviewed-by: Stefan Metzmacher <metze@samba.org>\\nReviewed-by: David Disseldorp <ddiss@suse.de>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: The code appears to be clean and does not contain any obvious security vulnerabilities.\n",
            "JSON Object: {\n",
            "    \"func\": \"static void cbq_link_class(struct cbq_class *this)\\n{\\n\\tstruct cbq_sched_data *q = qdisc_priv(this->qdisc);\\n\\tunsigned h = cbq_hash(this->classid);\\n\\tstruct cbq_class *parent = this->tparent;\\n\\n\\tthis->sibling = this;\\n\\tthis->next = q->classes[h];\\n\\tq->classes[h] = this;\\n\\n\\tif (parent == NULL)\\n\\t\\treturn;\\n\\n\\tif (parent->children == NULL) {\\n\\t\\tparent->children = this;\\n\\t} else {\\n\\t\\tthis->sibling = parent->children->sibling;\\n\\t\\tparent->children->sibling = this;\\n\\t}\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-200\"\n",
            "    ],\n",
            "    \"message\": \"[NETLINK]: Missing padding fields in dumped structures\\n\\nPlug holes with padding fields and initialized them to zero.\\n\\nSigned-off-by: Patrick McHardy <kaber@trash.net>\\nSigned-off-by: David S. Miller <davem@davemloft.net>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: This function appears to be clean and does not have any obvious security vulnerabilities. It allocates memory for a `struct pci_bar_info` using `kmalloc`, checks if the allocation was successful, reads device bar information using the `read_dev_bar` function, sets the `which` field of the `bar` structure to 0, and then returns the `bar` structure.\n",
            "\n",
            "However, it is important to note that without knowing the implementation of the `read_dev_bar` function, we cannot fully determine if there are any potential vulnerabilities in the code. It is always recommended to carefully review and validate the implementation of any function used in a code snippet for potential security risks.\n",
            "JSON Object: {\n",
            "    \"func\": \"static void *rom_init(struct pci_dev *dev, int offset)\\n{\\n\\tstruct pci_bar_info *bar = kmalloc(sizeof(*bar), GFP_KERNEL);\\n\\n\\tif (!bar)\\n\\t\\treturn ERR_PTR(-ENOMEM);\\n\\n\\tread_dev_bar(dev, bar, offset, ~PCI_ROM_ADDRESS_ENABLE);\\n\\tbar->which = 0;\\n\\n\\treturn bar;\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-284\",\n",
            "        \"CWE-264\"\n",
            "    ],\n",
            "    \"message\": \"xen-pciback: limit guest control of command register\\n\\nOtherwise the guest can abuse that control to cause e.g. PCIe\\nUnsupported Request responses by disabling memory and/or I/O decoding\\nand subsequently causing (CPU side) accesses to the respective address\\nranges, which (depending on system configuration) may be fatal to the\\nhost.\\n\\nNote that to alter any of the bits collected together as\\nPCI_COMMAND_GUEST permissive mode is now required to be enabled\\nglobally or on the specific device.\\n\\nThis is CVE-2015-2150 / XSA-120.\\n\\nSigned-off-by: Jan Beulich <jbeulich@suse.com>\\nReviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>\\nCc: <stable@vger.kernel.org>\\nSigned-off-by: David Vrabel <david.vrabel@citrix.com>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: The code provided appears to be clean and does not contain any obvious security vulnerabilities. It is simply a function that checks for certain conditions and sets the `disabled` flag for specific menu items based on those conditions.\n",
            "JSON Object: {\n",
            "    \"func\": \"static void validlistcheck(GWindow gw, struct gmenuitem *mi, GEvent *UNUSED(e)) {\\n    FontView *fv = (FontView *) GDrawGetUserData(gw);\\n    int anychars = FVAnyCharSelected(fv);\\n\\n    for ( mi = mi->sub; mi->ti.text!=NULL || mi->ti.line ; ++mi ) {\\n\\tswitch ( mi->mid ) {\\n\\t  case MID_FindProblems:\\n\\t    mi->ti.disabled = anychars==-1;\\n\\t  break;\\n\\t  case MID_Validate:\\n\\t    mi->ti.disabled = fv->b.sf->strokedfont || fv->b.sf->multilayer;\\n\\t  break;\\n        }\\n    }\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-119\",\n",
            "        \"CWE-787\"\n",
            "    ],\n",
            "    \"message\": \"Warn users before discarding their unsaved scripts (#3852)\\n\\n* Warn users before discarding their unsaved scripts\\r\\n\\r\\nThis closes #3846.\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: This function does not contain any security vulnerabilities as it is properly checking for NULL pointer when accessing the `q` structure. Additionally, it is correctly returning an error code if the queue is invalid. The use of `test_bit` function is safe and there are no buffer overflows or input validation issues in this code snippet. Therefore, the code is clean.\n",
            "JSON Object: {\n",
            "    \"func\": \"int snd_seq_queue_is_used(int queueid, int client)\\n{\\n\\tstruct snd_seq_queue *q;\\n\\tint result;\\n\\n\\tq = queueptr(queueid);\\n\\tif (q == NULL)\\n\\t\\treturn -EINVAL; /* invalid queue */\\n\\tresult = test_bit(client, q->clients_bitmap) ? 1 : 0;\\n\\tqueuefree(q);\\n\\treturn result;\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-362\"\n",
            "    ],\n",
            "    \"message\": \"ALSA: seq: Fix race at timer setup and close\\n\\nALSA sequencer code has an open race between the timer setup ioctl and\\nthe close of the client.  This was triggered by syzkaller fuzzer, and\\na use-after-free was caught there as a result.\\n\\nThis patch papers over it by adding a proper queue->timer_mutex lock\\naround the timer-related calls in the relevant code path.\\n\\nReported-by: Dmitry Vyukov <dvyukov@google.com>\\nTested-by: Dmitry Vyukov <dvyukov@google.com>\\nCc: <stable@vger.kernel.org>\\nSigned-off-by: Takashi Iwai <tiwai@suse.de>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: The given function `skb_copy_and_csum_dev` does not contain any obvious security vulnerabilities. The function seems to be handling copying and checksum calculation for network packets (sk_buff). The use of pointers and offsets is within the bounds of the buffer being accessed.\n",
            "\n",
            "However, without additional context on how the sk_buff structure is created and used elsewhere in the codebase, it is difficult to make a comprehensive analysis for potential security vulnerabilities. It is important to ensure that the sk_buff structure is properly initialized and managed to prevent buffer overflows or other memory corruption issues. Additionally, verifying the inputs to the function and ensuring proper error handling are crucial for overall security.\n",
            "JSON Object: {\n",
            "    \"func\": \"void skb_copy_and_csum_dev(const struct sk_buff *skb, u8 *to)\\n{\\n\\t__wsum csum;\\n\\tlong csstart;\\n\\n\\tif (skb->ip_summed == CHECKSUM_PARTIAL)\\n\\t\\tcsstart = skb_checksum_start_offset(skb);\\n\\telse\\n\\t\\tcsstart = skb_headlen(skb);\\n\\n\\tBUG_ON(csstart > skb_headlen(skb));\\n\\n\\tskb_copy_from_linear_data(skb, to, csstart);\\n\\n\\tcsum = 0;\\n\\tif (csstart != skb->len)\\n\\t\\tcsum = skb_copy_and_csum_bits(skb, csstart, to + csstart,\\n\\t\\t\\t\\t\\t      skb->len - csstart, 0);\\n\\n\\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\\n\\t\\tlong csstuff = csstart + skb->csum_offset;\\n\\n\\t\\t*((__sum16 *)(to + csstuff)) = csum_fold(csum);\\n\\t}\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-416\"\n",
            "    ],\n",
            "    \"message\": \"core, nfqueue, openvswitch: Orphan frags in skb_zerocopy and handle errors\\n\\nskb_zerocopy can copy elements of the frags array between skbs, but it doesn't\\norphan them. Also, it doesn't handle errors, so this patch takes care of that\\nas well, and modify the callers accordingly. skb_tx_error() is also added to\\nthe callers so they will signal the failed delivery towards the creator of the\\nskb.\\n\\nSigned-off-by: Zoltan Kiss <zoltan.kiss@citrix.com>\\nSigned-off-by: David S. Miller <davem@davemloft.net>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: This function may be vulnerable to a buffer overflow if the channel_map array in the image parameter is not properly validated. If the offset value in the channel_map array is not within the bounds of the pixel array, it could cause the function to access memory outside of the pixel array, leading to potential security vulnerabilities.\n",
            "\n",
            "It is important to ensure that the offset value is properly validated before accessing the pixel array to prevent buffer overflow vulnerabilities.\n",
            "JSON Object: {\n",
            "    \"func\": \"static inline Quantum GetPixelCr(const Image *restrict image,\\n  const Quantum *restrict pixel)\\n{\\n  return(pixel[image->channel_map[CrPixelChannel].offset]);\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-119\",\n",
            "        \"CWE-787\"\n",
            "    ],\n",
            "    \"message\": \"\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: This function appears to be vulnerable to a potential buffer overflow as it does not contain any bounds checking when accessing the entries array. If the entry_count value is greater than the actual number of entries in the array, it could lead to accessing memory outside of the allocated array, resulting in undefined behavior.\n",
            "\n",
            "To mitigate this vulnerability, bounds checking should be added to ensure that the loop does not access entries beyond the allocated memory. Additionally, proper input validation should be done to ensure that the input parameters are valid and within expected ranges.\n",
            "JSON Object: {\n",
            "    \"func\": \"static void release_tree_content_recursive(struct tree_content *t)\\n{\\n\\tunsigned int i;\\n\\tfor (i = 0; i < t->entry_count; i++)\\n\\t\\trelease_tree_entry(t->entries[i]);\\n\\trelease_tree_content(t);\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [],\n",
            "    \"message\": \"fast-import: disallow \\\"feature export-marks\\\" by default\\n\\nThe fast-import stream command \\\"feature export-marks=<path>\\\" lets the\\nstream write marks to an arbitrary path. This may be surprising if you\\nare running fast-import against an untrusted input (which otherwise\\ncannot do anything except update Git objects and refs).\\n\\nLet's disallow the use of this feature by default, and provide a\\ncommand-line option to re-enable it (you can always just use the\\ncommand-line --export-marks as well, but the in-stream version provides\\nan easy way for exporters to control the process).\\n\\nThis is a backwards-incompatible change, since the default is flipping\\nto the new, safer behavior. However, since the main users of the\\nin-stream versions would be import/export-based remote helpers, and\\nsince we trust remote helpers already (which are already running\\narbitrary code), we'll pass the new option by default when reading a\\nremote helper's stream. This should minimize the impact.\\n\\nNote that the implementation isn't totally simple, as we have to work\\naround the fact that fast-import doesn't parse its command-line options\\nuntil after it has read any \\\"feature\\\" lines from the stream. This is how\\nit lets command-line options override in-stream. But in our case, it's\\nimportant to parse the new --allow-unsafe-features first.\\n\\nThere are three options for resolving this:\\n\\n  1. Do a separate \\\"early\\\" pass over the options. This is easy for us to\\n     do because there are no command-line options that allow the\\n     \\\"unstuck\\\" form (so there's no chance of us mistaking an argument\\n     for an option), though it does introduce a risk of incorrect\\n     parsing later (e.g,. if we convert to parse-options).\\n\\n  2. Move the option parsing phase back to the start of the program, but\\n     teach the stream-reading code never to override an existing value.\\n     This is tricky, because stream \\\"feature\\\" lines override each other\\n     (meaning we'd have to start tracking the source for every option).\\n\\n  3. Accept that we might parse a \\\"feature export-marks\\\" line that is\\n     forbidden, as long we don't _act_ on it until after we've parsed\\n     the command line options.\\n\\n     This would, in fact, work with the current code, but only because\\n     the previous patch fixed the export-marks parser to avoid touching\\n     the filesystem.\\n\\n     So while it works, it does carry risk of somebody getting it wrong\\n     in the future in a rather subtle and unsafe way.\\n\\nI've gone with option (1) here as simple, safe, and unlikely to cause\\nregressions.\\n\\nThis fixes CVE-2019-1348.\\n\\nSigned-off-by: Jeff King <peff@peff.net>\"\n",
            "}\n",
            "Predicted: 1 Actual: 0\n",
            "Full Response: This function appears to be mainly focused on accessing and returning a tcp_md5sig_pool pointer based on the CPU input provided. However, there are some security vulnerabilities that can be identified in this code:\n",
            "\n",
            "1. Lack of Input Validation: The function takes an integer `cpu` as input, but it does not validate the input to ensure it is within a valid range. This could potentially lead to out-of-bounds memory access or other vulnerabilities if the input is manipulated by an attacker.\n",
            "\n",
            "2. No Memory Allocation Checks: The function does not check if memory allocation for the tcp_md5sig_pool pointer was successful. If the memory allocation fails, it could lead to a NULL pointer dereference issue.\n",
            "\n",
            "3. Potential Race Condition: The function uses spin locks to protect access to the tcp_md5sig_pool, but there could still be potential race conditions if multiple threads access the function simultaneously. This could lead to data corruption or inconsistent results.\n",
            "\n",
            "Overall, while this code is not excessively vulnerable, it could benefit from input validation, memory allocation checks, and a review of the concurrency handling to improve security and reliability.\n",
            "JSON Object: {\n",
            "    \"func\": \"struct tcp_md5sig_pool *__tcp_get_md5sig_pool(int cpu)\\n{\\n\\tstruct tcp_md5sig_pool * __percpu *p;\\n\\tspin_lock_bh(&tcp_md5sig_pool_lock);\\n\\tp = tcp_md5sig_pool;\\n\\tif (p)\\n\\t\\ttcp_md5sig_users++;\\n\\tspin_unlock_bh(&tcp_md5sig_pool_lock);\\n\\treturn (p ? *per_cpu_ptr(p, cpu) : NULL);\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-400\",\n",
            "        \"CWE-119\",\n",
            "        \"CWE-703\"\n",
            "    ],\n",
            "    \"message\": \"net: Fix oops from tcp_collapse() when using splice()\\n\\ntcp_read_sock() can have a eat skbs without immediately advancing copied_seq.\\nThis can cause a panic in tcp_collapse() if it is called as a result\\nof the recv_actor dropping the socket lock.\\n\\nA userspace program that splices data from a socket to either another\\nsocket or to a file can trigger this bug.\\n\\nSigned-off-by: Steven J. Magnani <steve@digidescorp.com>\\nSigned-off-by: David S. Miller <davem@davemloft.net>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Full Response: This function is not vulnerable to security vulnerabilities. It uses proper locking mechanisms to ensure thread safety while accessing the page tree and checking for page existence. It also checks for potential race conditions by verifying if the page has been truncated while sleeping. Overall, the code is clean from security vulnerabilities.\n",
            "JSON Object: {\n",
            "    \"func\": \"struct page *find_lock_page(struct address_space *mapping,\\n\\t\\t\\t\\tpgoff_t offset)\\n{\\n\\tstruct page *page;\\n\\nrepeat:\\n\\tread_lock_irq(&mapping->tree_lock);\\n\\tpage = radix_tree_lookup(&mapping->page_tree, offset);\\n\\tif (page) {\\n\\t\\tpage_cache_get(page);\\n\\t\\tif (TestSetPageLocked(page)) {\\n\\t\\t\\tread_unlock_irq(&mapping->tree_lock);\\n\\t\\t\\t__lock_page(page);\\n\\n\\t\\t\\t/* Has the page been truncated while we slept? */\\n\\t\\t\\tif (unlikely(page->mapping != mapping)) {\\n\\t\\t\\t\\tunlock_page(page);\\n\\t\\t\\t\\tpage_cache_release(page);\\n\\t\\t\\t\\tgoto repeat;\\n\\t\\t\\t}\\n\\t\\t\\tVM_BUG_ON(page->index != offset);\\n\\t\\t\\tgoto out;\\n\\t\\t}\\n\\t}\\n\\tread_unlock_irq(&mapping->tree_lock);\\nout:\\n\\treturn page;\\n}\",\n",
            "    \"target\": 0,\n",
            "    \"cwe\": [\n",
            "        \"CWE-20\"\n",
            "    ],\n",
            "    \"message\": \"fix writev regression: pan hanging unkillable and un-straceable\\n\\nFrederik Himpe reported an unkillable and un-straceable pan process.\\n\\nZero length iovecs can go into an infinite loop in writev, because the\\niovec iterator does not always advance over them.\\n\\nThe sequence required to trigger this is not trivial. I think it\\nrequires that a zero-length iovec be followed by a non-zero-length iovec\\nwhich causes a pagefault in the atomic usercopy. This causes the writev\\ncode to drop back into single-segment copy mode, which then tries to\\ncopy the 0 bytes of the zero-length iovec; a zero length copy looks like\\na failure though, so it loops.\\n\\nPut a test into iov_iter_advance to catch zero-length iovecs. We could\\njust put the test in the fallback path, but I feel it is more robust to\\nskip over zero-length iovecs throughout the code (iovec iterator may be\\nused in filesystems too, so it should be robust).\\n\\nSigned-off-by: Nick Piggin <npiggin@suse.de>\\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\"\n",
            "}\n",
            "Predicted: 0 Actual: 0\n",
            "Accuracy: 0.9\n"
          ]
        }
      ]
    }
  ]
}